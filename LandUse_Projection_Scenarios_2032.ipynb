{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIxKOqyixd66"
      },
      "outputs": [],
      "source": [
        "# -------------------- Mount Google Drive --------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cukup pasang rasterio (dan shapely bila diperlukan). Jangan menyentuh numpy/pandas/scipy/ sklearn bawaan Colab.\n",
        "!pip install -q \"rasterio==1.4.1\" \"shapely==2.0.6\""
      ],
      "metadata": {
        "id": "GvEW8G0hxi69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BAU Scenario**"
      ],
      "metadata": {
        "id": "kHQMfj1MxnNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# BAU 2032 — CA–Markov (single script, Colab-ready)\n",
        "# ============================================================\n",
        "# - Installs dependencies (with ABI-safe pinned versions) and mounts Google Drive\n",
        "# - Loads PL_2016, PL_2024, and SUIT_2016_all.npy\n",
        "# - Aggregates suitability → 3 channels (Sawah, Terbangun, Lainnya)\n",
        "# - Builds Markov transition matrix T(2016→2024)\n",
        "# - Runs quantity-constrained CA from 2024 → 2032\n",
        "# - Saves raster output, CSV area summary, and subplot visualization\n",
        "# ============================================================\n",
        "\n",
        "# -------------------- Bootstrap: dependencies & mount --------------------\n",
        "import sys, os\n",
        "\n",
        "def _maybe_install_and_restart():\n",
        "    try:\n",
        "        import rasterio  # noqa\n",
        "        import numpy as np  # noqa\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(\"[Setup] Installing pinned versions for compatibility...\", e)\n",
        "        # Install versions compatible with Colab\n",
        "        # Note: This will restart the runtime after installation\n",
        "        os.system(\n",
        "            \"pip -q install --upgrade --force-reinstall --no-cache-dir \"\n",
        "            \" \\\"numpy==1.26.4\\\" \\\"rasterio==1.3.9\\\" \"\n",
        "            \" \\\"scipy==1.11.4\\\" \\\"pandas==2.1.4\\\" \\\"matplotlib==3.8.2\\\" \"\n",
        "            \" \\\"scikit-learn==1.3.2\\\" \\\"shapely==2.0.1\\\"\"\n",
        "        )\n",
        "        print(\"[Setup] Restarting runtime to finalize installations...\")\n",
        "        os.kill(os.getpid(), 9)\n",
        "\n",
        "_maybe_install_and_restart()\n",
        "\n",
        "# Mount Google Drive (idempotent)\n",
        "try:\n",
        "    from google.colab import drive  # type: ignore\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "except Exception as _e:\n",
        "    print(\"[Info] Not running on Colab or Drive mount failed. Proceeding without mount.\")\n",
        "\n",
        "# -------------------- Imports (after setup) --------------------\n",
        "import numpy as np\n",
        "import rasterio\n",
        "import pandas as pd\n",
        "from scipy.ndimage import uniform_filter\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "# -------------------- Paths --------------------\n",
        "SAWAH_DIR = \"/content/drive/MyDrive/Sawah2\"    # expects PL_2016.tif, PL_2024.tif, SUIT_2016_all.npy\n",
        "CHGDIR    = \"/content/drive/MyDrive/Land Use/Change_Analysis\"\n",
        "REP_DIR   = os.path.join(CHGDIR, \"reports\")\n",
        "os.makedirs(CHGDIR, exist_ok=True); os.makedirs(REP_DIR, exist_ok=True)\n",
        "\n",
        "# -------------------- Utility functions --------------------\n",
        "\n",
        "def read_raster(path):\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"File not found: {path}\")\n",
        "    with rasterio.open(path) as src:\n",
        "        return src.read(1), src.profile\n",
        "\n",
        "\n",
        "def save_with_colormap(arr, profile, path, nodata=255):\n",
        "    prof = profile.copy()\n",
        "    prof.update(dtype=rasterio.uint8, nodata=nodata, count=1, compress=\"lzw\",\n",
        "                height=arr.shape[0], width=arr.shape[1])\n",
        "    with rasterio.open(path, 'w', **prof) as dst:\n",
        "        dst.write(arr.astype(np.uint8), 1)\n",
        "        dst.write_colormap(1, {\n",
        "            1:(46,139,87,255),   # Sawah\n",
        "            2:(220,20,60,255),   # Terbangun\n",
        "            3:(30,144,255,255),  # Lainnya\n",
        "            255:(0,0,0,0)\n",
        "        })\n",
        "    print(\"✅ Saved:\", path)\n",
        "\n",
        "\n",
        "def ha_per_pixel(profile):\n",
        "    t = profile['transform']\n",
        "    return abs(t.a)*abs(t.e)/10_000.0\n",
        "\n",
        "\n",
        "def area_by_class(arr, ha_pix):\n",
        "    return {c: float((arr==c).sum())*ha_pix for c in (1,2,3)}\n",
        "\n",
        "# -------------------- Load maps & suitability --------------------\n",
        "PL_16, _       = read_raster(os.path.join(SAWAH_DIR, \"PL_2016.tif\"))\n",
        "PL_24, PROFILE = read_raster(os.path.join(SAWAH_DIR, \"PL_2024.tif\"))\n",
        "H, W = PL_24.shape\n",
        "\n",
        "SUIT_ALL_PATH     = os.path.join(SAWAH_DIR, \"SUIT_2016_all.npy\")\n",
        "SUIT_CLASSES_PATH = os.path.join(SAWAH_DIR, \"SUIT_2016_all_classes.npy\")  # optional\n",
        "if not os.path.exists(SUIT_ALL_PATH):\n",
        "    raise FileNotFoundError(f\"Suitability file not found: {SUIT_ALL_PATH}\")\n",
        "\n",
        "suits = np.load(SUIT_ALL_PATH)\n",
        "if suits.ndim != 3 or suits.shape[1:] != (H,W):\n",
        "    raise ValueError(f\"Invalid SUIT_2016_all.npy dimensions: {suits.shape}; expected (C,{H},{W})\")\n",
        "\n",
        "if os.path.exists(SUIT_CLASSES_PATH):\n",
        "    suit_classes = np.load(SUIT_CLASSES_PATH)\n",
        "else:\n",
        "    suit_classes = np.arange(suits.shape[0])\n",
        "\n",
        "# Normalize per-pixel probabilities to sum = 1\n",
        "suits = np.nan_to_num(suits.astype(np.float32), nan=0.0, posinf=0.0, neginf=0.0)\n",
        "ss = suits.sum(axis=0, keepdims=True); ss[ss==0]=1\n",
        "suits = suits/ss\n",
        "\n",
        "# Aggregate to 3 channels: Sawah(1), Terbangun(2), Lainnya(rest)\n",
        "GROUPS = {\"Sawah\":[1], \"Lahan_Terbangun\":[2], \"Lainnya\":\"rest\"}\n",
        "cls_list = list(suit_classes.tolist())\n",
        "stacks, names, used = [], [], set()\n",
        "for gname, members in GROUPS.items():\n",
        "    if members == \"rest\":\n",
        "        idx = [i for i in range(suits.shape[0]) if i not in used]\n",
        "    else:\n",
        "        idx = [cls_list.index(m) for m in members if m in cls_list]\n",
        "    if len(idx) == 0:\n",
        "        stacks.append(np.zeros((H,W), np.float32))\n",
        "    else:\n",
        "        used.update(idx)\n",
        "        stacks.append(np.nansum(suits[idx,...], axis=0).astype(np.float32))\n",
        "    names.append(gname)\n",
        "SUIT_3 = np.stack(stacks, axis=0).astype(np.float32)\n",
        "ss3 = SUIT_3.sum(axis=0, keepdims=True); ss3[ss3==0]=1\n",
        "SUIT_3 = SUIT_3/ss3\n",
        "print(\"Aggregated channels:\", names)\n",
        "\n",
        "# -------------------- Markov transition matrix T(2016→2024) --------------------\n",
        "\n",
        "def transition_matrix(start, end, num_classes=3, nodata=255):\n",
        "    M = np.zeros((num_classes,num_classes), np.float64)\n",
        "    m = (start!=nodata) & (end!=nodata)\n",
        "    s = start[m]; e = end[m]\n",
        "    for i in range(1, num_classes+1):\n",
        "        sel = (s==i)\n",
        "        if sel.any():\n",
        "            for j in range(1, num_classes+1):\n",
        "                M[i-1, j-1] = np.sum(e[sel]==j)\n",
        "    row = M.sum(axis=1, keepdims=True); row[row==0]=1\n",
        "    return M/row\n",
        "\n",
        "T_16_24 = transition_matrix(PL_16, PL_24)\n",
        "print(\"\\n=== MARKOV TRANSITION 2016→2024 ===\\n\", np.round(T_16_24, 4))\n",
        "\n",
        "# -------------------- Quantity-constrained CA (2024→2032) --------------------\n",
        "\n",
        "def neighborhood_fraction(label_map, cls, size=5):\n",
        "    return uniform_filter((label_map==cls).astype(np.float32), size=size, mode='nearest')\n",
        "\n",
        "\n",
        "def compute_scores(current_map, T, suit3, neigh_weight=0.25, neigh_size=5, nodata=255):\n",
        "    H,W = current_map.shape\n",
        "    valid = (current_map!=nodata)\n",
        "    ii, jj = np.where(valid)\n",
        "\n",
        "    n1 = neighborhood_fraction(current_map, 1, neigh_size)\n",
        "    n2 = neighborhood_fraction(current_map, 2, neigh_size)\n",
        "    n3 = neighborhood_fraction(current_map, 3, neigh_size)\n",
        "    LP = (1.0 - neigh_weight)*suit3 + neigh_weight*np.stack([n1,n2,n3], axis=0)\n",
        "\n",
        "    cur = current_map[valid]\n",
        "    S = np.zeros((3, ii.size), dtype=np.float32)\n",
        "    for k in (1,2,3):\n",
        "        S[k-1,:] = T[cur-1, k-1] * LP[k-1, ii, jj]\n",
        "\n",
        "    order  = np.argsort(-S, axis=0)\n",
        "    best   = order[0,:] + 1\n",
        "    second = order[1,:] + 1\n",
        "    margin = S[order[0,:], np.arange(S.shape[1])] - S[order[1,:], np.arange(S.shape[1])]\n",
        "    return S, valid, (best, second, margin)\n",
        "\n",
        "\n",
        "def targets_from_markov(initial_map, T, nodata=255):\n",
        "    h0 = np.array([(initial_map==1).sum(), (initial_map==2).sum(), (initial_map==3).sum()], float)\n",
        "    tgt_f = h0 @ T\n",
        "    tgt = np.floor(tgt_f).astype(int)\n",
        "    gap = int(h0.sum() - tgt.sum())\n",
        "    if gap!=0:\n",
        "        frac = tgt_f - np.floor(tgt_f); order = np.argsort(-frac)\n",
        "        for i in order[:abs(gap)]: tgt[i] += 1 if gap>0 else -1\n",
        "    return tgt\n",
        "\n",
        "\n",
        "def allocate_with_targets(S, valid_mask, target_counts, info, nodata=255, max_iter=5):\n",
        "    H,W = valid_mask.shape\n",
        "    ii, jj = np.where(valid_mask)\n",
        "    best, second, margin = info\n",
        "    alloc = best.copy()\n",
        "\n",
        "    def counts(v): return np.array([(v==1).sum(), (v==2).sum(), (v==3).sum()], np.int64)\n",
        "\n",
        "    def reassign(from_cls, to_cls, need):\n",
        "        if need<=0: return 0\n",
        "        idx_from = np.where(alloc==from_cls)[0]\n",
        "        if idx_from.size==0: return 0\n",
        "        idx2 = idx_from[ second[idx_from]==to_cls ]\n",
        "        if idx2.size==0: return 0\n",
        "        take = min(need, idx2.size)\n",
        "        sel = idx2[np.argsort(margin[idx2])[:take]]\n",
        "        alloc[sel] = to_cls\n",
        "        return take\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        diff = target_counts - counts(alloc)\n",
        "        if np.all(diff==0): break\n",
        "        for s_idx in np.argsort(diff):\n",
        "            if diff[s_idx] >= 0: continue\n",
        "            from_cls = s_idx+1; need_rm = -diff[s_idx]\n",
        "            for d_idx in np.where(diff>0)[0]:\n",
        "                to_cls = d_idx+1\n",
        "                moved = reassign(from_cls, to_cls, min(need_rm, diff[d_idx]))\n",
        "                need_rm -= moved; diff[d_idx] -= moved\n",
        "                if need_rm<=0: break\n",
        "\n",
        "    out = np.full((H,W), nodata, np.uint8)\n",
        "    out[ii, jj] = alloc.astype(np.uint8)\n",
        "    return out\n",
        "\n",
        "\n",
        "def quantity_constrained_ca(initial_map, T, suit3,\n",
        "                            neigh_weight=0.25, neigh_size=5, qc_iters=3, nodata=255):\n",
        "    target = targets_from_markov(initial_map, T, nodata)\n",
        "    cur = initial_map.copy()\n",
        "    for _ in range(qc_iters):\n",
        "        S, valid, info = compute_scores(cur, T, suit3,\n",
        "                                        neigh_weight=neigh_weight, neigh_size=neigh_size, nodata=nodata)\n",
        "        cur = allocate_with_targets(S, valid, target, info, nodata=nodata, max_iter=5)\n",
        "    return cur, target\n",
        "\n",
        "# Run CA from 2024 → 2032 using T(16→24)\n",
        "pred_2032, target_2032 = quantity_constrained_ca(\n",
        "    initial_map=PL_24, T=T_16_24, suit3=SUIT_3,\n",
        "    neigh_weight=0.25, neigh_size=5, qc_iters=3, nodata=255\n",
        ")\n",
        "\n",
        "# -------------------- Save outputs --------------------\n",
        "out_tif = os.path.join(CHGDIR, \"Prediksi_2032_BAU_CA_Markov_from2016to2024.tif\")\n",
        "save_with_colormap(pred_2032, PROFILE, out_tif)\n",
        "\n",
        "ha_pix = ha_per_pixel(PROFILE)\n",
        "luas24 = area_by_class(PL_24, ha_pix)\n",
        "luas32 = area_by_class(pred_2032, ha_pix)\n",
        "\n",
        "summary = pd.DataFrame([\n",
        "    [\"Sawah\",     luas24[1], luas32[1], luas32[1]-luas24[1]],\n",
        "    [\"Terbangun\", luas24[2], luas32[2], luas32[2]-luas24[2]],\n",
        "    [\"Lainnya\",   luas24[3], luas32[3], luas32[3]-luas24[3]],\n",
        "], columns=[\"Class\",\"2024 (ha)\",\"2032 BAU (ha)\",\"Δ(ha)\"])\n",
        "\n",
        "csv_out = os.path.join(REP_DIR, \"area_summary_BAU_2032_from2016to2024.csv\")\n",
        "summary.to_csv(csv_out, index=False)\n",
        "print(\"\\n=== AREA SUMMARY ===\\n\", summary.round(2))\n",
        "print(\"✅ Saved:\", csv_out)\n",
        "\n",
        "# -------------------- Visualization --------------------\n",
        "\n",
        "def show_classmap(arr, title, nodata=255):\n",
        "    labels = ['Sawah (1)', 'Terbangun (2)', 'Lainnya (3)']\n",
        "    cmap = ListedColormap(['#2e8b57', '#dc143c', '#1e90ff'])\n",
        "    m = np.ma.masked_where(arr == nodata, arr)\n",
        "    plt.imshow(m, cmap=cmap, vmin=1, vmax=3)\n",
        "    plt.title(title, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "    patches = [mpatches.Patch(color=cmap(i), label=labels[i]) for i in range(3)]\n",
        "    return patches\n",
        "\n",
        "plt.figure(figsize=(12,6), dpi=600)\n",
        "plt.subplot(1,2,2)\n",
        "legend_handles = show_classmap(pred_2032, \"BAU Scenario\")\n",
        "\n",
        "plt.legend(handles=legend_handles,\n",
        "           loc='lower center',\n",
        "           bbox_to_anchor=(0.5, -0.05),\n",
        "           ncol=3,\n",
        "           frameon=False,\n",
        "           prop={'weight': 'bold'})\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"✅ Completed.\")\n"
      ],
      "metadata": {
        "id": "eaQVMkNixsdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ZRFP Scenario**"
      ],
      "metadata": {
        "id": "v5xpUXjKx27e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# PROJECTION 2032 — Probabilistic CA + Ske_B4B5 (super-protect rice fields; no Markov)\n",
        "# ============================================================\n",
        "# - WITHOUT transition matrix (no T / T²)\n",
        "# - Protection: max 10% of rice fields within B4B5 allowed to convert (adaptive by pressure)\n",
        "# - Endogenous (no quota): E = r_global(2016→2024) × POLICY_INTENSITY\n",
        "# - Distribution: Random Forest suitability (BU) + neighborhood of built-up cells\n",
        "# - BU absorbing; only 1/3 → 2 transitions allowed (1→3 blocked)\n",
        "# - Aggressive paddy-loss reduction: weak source-share, protection & soft caps, edge softener\n",
        "# ============================================================\n",
        "\n",
        "# -------------------- Bootstrap: dependencies & mount --------------------\n",
        "import sys, os\n",
        "def _maybe_install_and_restart():\n",
        "    try:\n",
        "        import rasterio  # noqa\n",
        "        import numpy as np  # noqa\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(\"[Setup] Installing pinned versions ...\", e)\n",
        "        os.system(\n",
        "            \"pip -q install --upgrade --force-reinstall --no-cache-dir \"\n",
        "            \" \\\"numpy==1.26.4\\\" \\\"rasterio==1.3.9\\\" \"\n",
        "            \" \\\"scipy==1.11.4\\\" \\\"pandas==2.1.4\\\" \\\"matplotlib==3.8.2\\\" \"\n",
        "            \" \\\"scikit-learn==1.3.2\\\" \\\"shapely==2.0.1\\\"\"\n",
        "        )\n",
        "        os.kill(os.getpid(), 9)\n",
        "_maybe_install_and_restart()\n",
        "\n",
        "try:\n",
        "    from google.colab import drive  # type: ignore\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "except Exception:\n",
        "    print(\"[Info] Drive mount skipped.\")\n",
        "\n",
        "# -------------------- Imports --------------------\n",
        "import numpy as np, rasterio, pandas as pd\n",
        "from scipy.ndimage import uniform_filter\n",
        "import matplotlib.pyplot as plt, matplotlib.patches as mpatches\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "# -------------------- Paths --------------------\n",
        "SAWAH_DIR = \"/content/drive/MyDrive/Sawah2\"    # PL_2016.tif, PL_2024.tif, SUIT_2016_all.npy, Ske_B4B5.tif\n",
        "CHGDIR    = \"/content/drive/MyDrive/Land Use/Change_Analysis\"\n",
        "REP_DIR   = os.path.join(CHGDIR, \"reports\")\n",
        "os.makedirs(CHGDIR, exist_ok=True); os.makedirs(REP_DIR, exist_ok=True)\n",
        "\n",
        "# -------------------- Constants & Settings --------------------\n",
        "NODATA       = 255\n",
        "NEIGH_WEIGHT = 0.40\n",
        "NEIGH_SIZE   = 9\n",
        "QC_ITERS     = 3          # ↓ fewer iterations to reduce repeated transitions\n",
        "RAND_SEED    = 42\n",
        "np.random.seed(RAND_SEED)\n",
        "\n",
        "# ======= Policy settings (strong anti-rice-field conversion, non-quota) =======\n",
        "POLICY_INTENSITY = 1.6     # ↓ reduces overall Σp (still endogenous)\n",
        "# Source weighting: weaken sawah, strengthen “others” (shift 3→2)\n",
        "W1 = 0.30                  # ↓ weaker drive 1→2\n",
        "W3 = 1.70                  # ↑ stronger drive 3→2\n",
        "\n",
        "# Rice field protection in B4B5 zones\n",
        "PROTECT_B4B5_FACTOR = 0.20 # extra penalty for 1→2 transitions inside B4B5\n",
        "CAP_P_SAWAH  = 0.020       # global cap for 1→2 probability (2% per iteration)\n",
        "CAP_P_B4B5   = 0.005       # extra-tight cap within B4B5 (0.5% per iteration)\n",
        "\n",
        "# Source sharing (non-quota; proportional pressure)\n",
        "USE_SOURCE_SHARE = True\n",
        "E1_SHARE = 0.15            # only 15% of expected expansion sourced from rice fields\n",
        "\n",
        "# -------------------- Utility functions --------------------\n",
        "def read_raster(path):\n",
        "    if not os.path.exists(path): raise FileNotFoundError(f\"File not found: {path}\")\n",
        "    with rasterio.open(path) as src: return src.read(1), src.profile\n",
        "\n",
        "def save_with_colormap(arr, profile, path, nodata=255):\n",
        "    prof = profile.copy()\n",
        "    prof.update(dtype=rasterio.uint8, nodata=nodata, count=1, compress=\"lzw\",\n",
        "                height=arr.shape[0], width=arr.shape[1])\n",
        "    with rasterio.open(path, 'w', **prof) as dst:\n",
        "        dst.write(arr.astype(np.uint8), 1)\n",
        "        dst.write_colormap(1, {1:(46,139,87,255), 2:(220,20,60,255), 3:(30,144,255,255), 255:(0,0,0,0)})\n",
        "    print(\"✅ Saved:\", path)\n",
        "\n",
        "def ha_per_pixel(profile):\n",
        "    t = profile['transform']; return abs(t.a)*abs(t.e)/10_000.0\n",
        "\n",
        "def area_by_class(arr, ha_pix):\n",
        "    return {c: float((arr==c).sum())*ha_pix for c in (1,2,3)}\n",
        "\n",
        "def neighborhood_fraction(label_map, cls, size=5):\n",
        "    return uniform_filter((label_map==cls).astype(np.float32), size=size, mode='nearest')\n",
        "\n",
        "# -------------------- Load data & suitability --------------------\n",
        "PL_16, _       = read_raster(os.path.join(SAWAH_DIR, \"PL_2016.tif\"))\n",
        "PL_24, PROFILE = read_raster(os.path.join(SAWAH_DIR, \"PL_2024.tif\"))\n",
        "H, W = PL_24.shape\n",
        "\n",
        "suits = np.load(os.path.join(SAWAH_DIR, \"SUIT_2016_all.npy\")).astype(np.float32)\n",
        "if suits.ndim != 3 or suits.shape[1:] != (H,W): raise ValueError(f\"SUIT_2016_all.npy shape {suits.shape} ≠ (C,{H},{W})\")\n",
        "classes_path = os.path.join(SAWAH_DIR, \"SUIT_2016_all_classes.npy\")\n",
        "suit_classes = np.load(classes_path) if os.path.exists(classes_path) else np.arange(suits.shape[0])\n",
        "\n",
        "suits = np.nan_to_num(suits, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "ss = suits.sum(axis=0, keepdims=True); ss[ss==0]=1; suits /= ss\n",
        "\n",
        "# Aggregate into 3 channels\n",
        "cls_list = list(suit_classes.tolist()); stacks, used = [], set()\n",
        "GROUPS = {\"Sawah\":[1], \"Lahan_Terbangun\":[2], \"Lainnya\":\"rest\"}\n",
        "for gname, members in GROUPS.items():\n",
        "    if members == \"rest\":\n",
        "        idx = [i for i in range(suits.shape[0]) if i not in used]\n",
        "    else:\n",
        "        idx = [cls_list.index(m) for m in members if m in cls_list]\n",
        "    stacks.append(np.nansum(suits[idx,...], axis=0).astype(np.float32) if len(idx) else np.zeros((H,W), np.float32))\n",
        "    used.update(idx)\n",
        "SUIT_3 = np.stack(stacks, axis=0).astype(np.float32)\n",
        "ss3 = SUIT_3.sum(axis=0, keepdims=True); ss3[ss3==0]=1; SUIT_3 /= ss3\n",
        "suit_BU = SUIT_3[1]\n",
        "\n",
        "# -------------------- Constraint Ske_B4B5 → eligibility --------------------\n",
        "B4B5_raw, _ = read_raster(os.path.join(SAWAH_DIR, \"Ske_B4B5.tif\"))\n",
        "IN_B4B5 = (np.isfinite(B4B5_raw) & (B4B5_raw > 0))\n",
        "\n",
        "sawah_in_b4b5 = (PL_24==1) & IN_B4B5\n",
        "n_sawah_b4b5  = int(sawah_in_b4b5.sum())\n",
        "quota10       = int(np.floor(0.10 * n_sawah_b4b5)) if n_sawah_b4b5>0 else 0\n",
        "\n",
        "nb2 = neighborhood_fraction(PL_24, 2, size=7)\n",
        "cand_score = 0.8*suit_BU + 0.2*nb2\n",
        "\n",
        "ALLOW_SAWAH_B4B5 = np.zeros_like(PL_24, dtype=bool)\n",
        "if quota10 > 0:\n",
        "    idx = np.flatnonzero(sawah_in_b4b5.ravel())\n",
        "    pick = idx if idx.size <= quota10 else idx[np.argsort(-cand_score.ravel()[idx])[:quota10]]\n",
        "    ALLOW_SAWAH_B4B5.ravel()[pick] = True\n",
        "\n",
        "# Eligibility: outside B4B5 = free; inside B4B5 = only top 10% allowed\n",
        "ELIGIBILITY = (~IN_B4B5) | ALLOW_SAWAH_B4B5\n",
        "valid = (PL_24 != NODATA)\n",
        "print(f\"10% quota of rice fields in B4B5 allowed: {quota10} pixels\")\n",
        "print(\"Eligible pixel proportion:\", float((ELIGIBILITY & valid).mean()))\n",
        "\n",
        "# -------------------- Pressure (no Markov) --------------------\n",
        "n2_2024 = neighborhood_fraction(PL_24, 2, NEIGH_SIZE)\n",
        "pressure_proj = (1.0 - NEIGH_WEIGHT)*suit_BU + NEIGH_WEIGHT*n2_2024\n",
        "\n",
        "# --- Edge softener: reduce high spikes of 1→2 near dense BU ---\n",
        "edge_softener = 1.0 - 0.5 * np.clip(n2_2024, 0.0, 1.0)  # up to 50% reduction near BU edges\n",
        "\n",
        "# -------------------- Endogenous calibration (non-BU→BU) --------------------\n",
        "valid16 = (PL_16 != NODATA); valid24 = (PL_24 != NODATA)\n",
        "nonBU16 = valid16 & ((PL_16==1) | (PL_16==3))\n",
        "toBU_glob = nonBU16 & valid24 & (PL_24==2)\n",
        "denom_glob = int(nonBU16.sum()); num_glob = int(toBU_glob.sum())\n",
        "r_global = (num_glob / denom_glob) if denom_glob > 0 else 0.0\n",
        "print(f\"[Calibration] r_global (2016→2024, non-BU→BU) = {r_global:.8f} | samples={denom_glob}\")\n",
        "\n",
        "cand_proj = ELIGIBILITY & valid & ((PL_24==1) | (PL_24==3))\n",
        "N_cand = int(cand_proj.sum())\n",
        "\n",
        "E = r_global * N_cand\n",
        "if E < 1 and N_cand > 0: E = max(1.0, 0.001 * N_cand)\n",
        "E *= POLICY_INTENSITY\n",
        "\n",
        "sum_press = float(np.nansum(pressure_proj[cand_proj])) if N_cand > 0 else 1.0\n",
        "alpha0 = (E / sum_press) if sum_press > 0 else 0.0\n",
        "\n",
        "p_map = np.zeros_like(pressure_proj, dtype=np.float32)\n",
        "p_map[cand_proj] = alpha0 * pressure_proj[cand_proj]\n",
        "\n",
        "# -------------------- Source weighting + protection & soft caps --------------------\n",
        "mask1 = cand_proj & (PL_24==1)\n",
        "mask3 = cand_proj & (PL_24==3)\n",
        "\n",
        "p_map[mask1] *= W1 * edge_softener[mask1]   # edge softener for rice fields\n",
        "p_map[mask3] *= W3\n",
        "\n",
        "mask1_B4B5 = mask1 & IN_B4B5\n",
        "p_map[mask1_B4B5] *= PROTECT_B4B5_FACTOR\n",
        "\n",
        "# Apply global & local caps\n",
        "p_map[mask1]      = np.minimum(p_map[mask1],      CAP_P_SAWAH)\n",
        "p_map[mask1_B4B5] = np.minimum(p_map[mask1_B4B5], CAP_P_B4B5)\n",
        "\n",
        "# -------------------- Source sharing (proportional pressure; still non-quota) --------------------\n",
        "if USE_SOURCE_SHARE:\n",
        "    cand1 = mask1\n",
        "    cand3 = mask3\n",
        "    E1 = E * E1_SHARE\n",
        "    E3 = E * (1.0 - E1_SHARE)\n",
        "\n",
        "    p1 = np.zeros_like(p_map, dtype=np.float32); p1[cand1] = p_map[cand1]\n",
        "    p3 = np.zeros_like(p_map, dtype=np.float32); p3[cand3] = p_map[cand3]\n",
        "\n",
        "    sum_p1 = float(np.nansum(p1[cand1])); sum_p3 = float(np.nansum(p3[cand3]))\n",
        "    p_map[:] = 0.0\n",
        "    if sum_p1 > 0: p_map[cand1] += p1[cand1] * (E1 / sum_p1)\n",
        "    if sum_p3 > 0: p_map[cand3] += p3[cand3] * (E3 / sum_p3)\n",
        "\n",
        "sum_p = float(np.nansum(p_map[cand_proj]))\n",
        "if sum_p > 0: p_map[cand_proj] *= (E / sum_p)\n",
        "\n",
        "p_map = np.clip(p_map, 0.0, 0.9)\n",
        "print(f\"[Prob-map] N_cand={N_cand} | E≈{E:.2f} | alpha0={alpha0:.6e} | Σp(after weights)≈{float(p_map[cand_proj].sum()):.2f}\")\n",
        "\n",
        "# -------------------- Probabilistic CA (BU absorbing; only 1/3→2) --------------------\n",
        "rng = np.random.default_rng(RAND_SEED)\n",
        "\n",
        "def step_probabilistic_CA(current_map, p_map, eligibility_mask, nodata=255):\n",
        "    out = current_map.copy()\n",
        "    valid = (current_map != nodata)\n",
        "    out[current_map==2] = 2   # BU absorbing\n",
        "    cand_to_BU = valid & eligibility_mask & ((current_map==1) | (current_map==3))\n",
        "    if np.any(cand_to_BU):\n",
        "        toss = rng.random(current_map.shape, dtype=np.float32)\n",
        "        to_BU = cand_to_BU & (toss < p_map)\n",
        "        out[to_BU] = 2\n",
        "    out[~valid] = nodata\n",
        "    return out\n",
        "\n",
        "cur = PL_24.copy()\n",
        "for _ in range(QC_ITERS):\n",
        "    cur = step_probabilistic_CA(cur, p_map, ELIGIBILITY, nodata=NODATA)\n",
        "pred_2032 = cur\n",
        "\n",
        "# -------------------- Save outputs & summary --------------------\n",
        "out_tif = os.path.join(CHGDIR, \"Prediksi_2032_CA_prob_SkeB4B5_ULTRAprotect_noMarkov.tif\")\n",
        "save_with_colormap(pred_2032, PROFILE, out_tif)\n",
        "\n",
        "ha_pix = ha_per_pixel(PROFILE)\n",
        "luas24 = area_by_class(PL_24, ha_pix)\n",
        "luas32 = area_by_class(pred_2032, ha_pix)\n",
        "\n",
        "summary = pd.DataFrame([\n",
        "    [\"Sawah\",     luas24[1], luas32[1], luas32[1]-luas24[1]],\n",
        "    [\"Terbangun\", luas24[2], luas32[2], luas32[2]-luas24[2]],\n",
        "    [\"Lainnya\",   luas24[3], luas32[3], luas32[3]-luas24[3]],\n",
        "], columns=[\"Class\",\"2024 (ha)\",\"2032 — Ske_B4B5 (ha)\",\"Δ(ha)\"])\n",
        "csv_out = os.path.join(REP_DIR, \"area_summary_2032_SkeB4B5_ULTRAprotect_noMarkov.csv\")\n",
        "summary.to_csv(csv_out, index=False)\n",
        "\n",
        "print(\"\\n=== PROJECTION 2032 — Ske_B4B5 (Prob.; no Markov; BU absorbing; 10% adaptive; ULTRA-protected rice fields) ===\")\n",
        "print(summary.round(2))\n",
        "print(\"✅ Saved:\", out_tif)\n",
        "print(\"✅ Saved:\", csv_out)\n",
        "\n",
        "# -------------------- Visualization --------------------\n",
        "def show_classmap(arr, title, nodata=255):\n",
        "    labels = ['Sawah (1)','Terbangun (2)','Lainnya (3)']\n",
        "    cmap = ListedColormap(['#2e8b57','#dc143c','#1e90ff'])\n",
        "    m = np.ma.masked_where(arr==nodata, arr)\n",
        "    plt.imshow(m, cmap=cmap, vmin=1, vmax=3); plt.title(title); plt.axis('off')\n",
        "    patches = [mpatches.Patch(color=cmap(i), label=labels[i]) for i in range(3)]\n",
        "    return patches\n",
        "\n",
        "plt.figure(figsize=(12,6), dpi=220)\n",
        "plt.subplot(1,2,1); _ = show_classmap(PL_24, \"OBSERVATION 2024\")\n",
        "plt.subplot(1,2,2); legend_handles = show_classmap(pred_2032, \"PREDICTION 2032 — Ske_B4B5 (ULTRA protect)\")\n",
        "plt.legend(handles=legend_handles, loc='lower center', bbox_to_anchor=(0.5, -0.05), ncol=3, frameon=False)\n",
        "plt.tight_layout(); plt.show()\n"
      ],
      "metadata": {
        "id": "6pH9peD7x1uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **UPI Scenario**"
      ],
      "metadata": {
        "id": "5PISSZaeyhPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# UPI Projection — Probabilistic CA (Prioritize Sawah; Policy Intensity; no Markov)\n",
        "# ============================================================\n",
        "# Endogenous changes derived from historical rate → projected to eligible areas (Ske_UPI)\n",
        "# through combined spatial pressures (road proximity, ZNT, neighborhood).\n",
        "# Rice fields (class 1) are prioritized for protection, but other classes (3) may still convert.\n",
        "# No manual target, fraction, or threshold is used.\n",
        "# The total magnitude of change is controlled by POLICY_INTENSITY.\n",
        "# ============================================================\n",
        "\n",
        "# -------------------- Bootstrap: dependencies & mount --------------------\n",
        "import sys, os\n",
        "def _maybe_install_and_restart():\n",
        "    try:\n",
        "        import rasterio  # noqa\n",
        "        import numpy as np  # noqa\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(\"[Setup] Installing pinned versions for compatibility...\", e)\n",
        "        os.system(\n",
        "            \"pip -q install --upgrade --force-reinstall --no-cache-dir \"\n",
        "            \" \\\"numpy==1.26.4\\\" \\\"rasterio==1.3.9\\\" \"\n",
        "            \" \\\"scipy==1.11.4\\\" \\\"pandas==2.1.4\\\" \\\"matplotlib==3.8.2\\\" \"\n",
        "            \" \\\"scikit-learn==1.3.2\\\" \\\"shapely==2.0.1\\\"\"\n",
        "        )\n",
        "        os.kill(os.getpid(), 9)\n",
        "_maybe_install_and_restart()\n",
        "\n",
        "try:\n",
        "    from google.colab import drive  # type: ignore\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "except Exception:\n",
        "    print(\"[Info] Not on Colab or Drive mount failed.\")\n",
        "\n",
        "# -------------------- Imports --------------------\n",
        "import numpy as np\n",
        "import rasterio\n",
        "import pandas as pd\n",
        "from scipy.ndimage import uniform_filter\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "# -------------------- Paths --------------------\n",
        "SAWAH_DIR = \"/content/drive/MyDrive/Sawah2\"    # PL_2016.tif, PL_2024.tif, SUIT_2016_all.npy, Ske_UPI.tif\n",
        "CHGDIR    = \"/content/drive/MyDrive/Land Use/Change_Analysis\"\n",
        "REP_DIR   = os.path.join(CHGDIR, \"reports\")\n",
        "os.makedirs(CHGDIR, exist_ok=True); os.makedirs(REP_DIR, exist_ok=True)\n",
        "\n",
        "# -------------------- Constants & CA Settings --------------------\n",
        "NODATA         = 255\n",
        "QC_ITERS       = 4           # number of CA iterations for spatial smoothing (not for quantity tuning)\n",
        "NEIGH_WEIGHT   = 0.40\n",
        "NEIGH_SIZE     = 9\n",
        "RAND_SEED      = 42          # reproducible results\n",
        "\n",
        "# -------------------- Policy Preferences --------------------\n",
        "W1 = 4.0   # multiplier to strengthen transition probability for sawah (class 1)\n",
        "W3 = 0.6   # mild reduction for other classes (class 3) — still allowed to change\n",
        "POLICY_INTENSITY = 3.0  # >1 increases expansion pressure (2.0–4.0 typical). Not a manual target.\n",
        "\n",
        "# -------------------- Utility Functions --------------------\n",
        "def read_raster(path):\n",
        "    if not os.path.exists(path): raise FileNotFoundError(f\"File not found: {path}\")\n",
        "    with rasterio.open(path) as src: return src.read(1), src.profile\n",
        "\n",
        "def save_with_colormap(arr, profile, path, nodata=255):\n",
        "    prof = profile.copy()\n",
        "    prof.update(dtype=rasterio.uint8, nodata=nodata, count=1, compress=\"lzw\",\n",
        "                height=arr.shape[0], width=arr.shape[1])\n",
        "    with rasterio.open(path, 'w', **prof) as dst:\n",
        "        dst.write(arr.astype(np.uint8), 1)\n",
        "        dst.write_colormap(1, {\n",
        "            1:(46,139,87,255),   # Sawah\n",
        "            2:(220,20,60,255),   # Terbangun\n",
        "            3:(30,144,255,255),  # Lainnya\n",
        "            255:(0,0,0,0)\n",
        "        })\n",
        "    print(\"✅ Saved:\", path)\n",
        "\n",
        "def ha_per_pixel(profile):\n",
        "    t = profile['transform']; return abs(t.a)*abs(t.e)/10_000.0\n",
        "\n",
        "def area_by_class(arr, ha_pix):\n",
        "    return {c: float((arr==c).sum())*ha_pix for c in (1,2,3)}\n",
        "\n",
        "def neighborhood_fraction(label_map, cls, size=5):\n",
        "    return uniform_filter((label_map==cls).astype(np.float32), size=size, mode='nearest')\n",
        "\n",
        "# -------------------- Load Maps & Suitability --------------------\n",
        "PL_16, _       = read_raster(os.path.join(SAWAH_DIR, \"PL_2016.tif\"))\n",
        "PL_24, PROFILE = read_raster(os.path.join(SAWAH_DIR, \"PL_2024.tif\"))\n",
        "H, W = PL_24.shape\n",
        "\n",
        "SUIT_ALL_PATH     = os.path.join(SAWAH_DIR, \"SUIT_2016_all.npy\")\n",
        "SUIT_CLASSES_PATH = os.path.join(SAWAH_DIR, \"SUIT_2016_all_classes.npy\")\n",
        "suits = np.load(SUIT_ALL_PATH)\n",
        "if suits.ndim != 3 or suits.shape[1:] != (H,W):\n",
        "    raise ValueError(f\"SUIT_2016_all.npy dimensions mismatch: {suits.shape}; expected (C,{H},{W})\")\n",
        "if os.path.exists(SUIT_CLASSES_PATH): suit_classes = np.load(SUIT_CLASSES_PATH)\n",
        "else: suit_classes = np.arange(suits.shape[0])\n",
        "\n",
        "# Normalize channels\n",
        "suits = np.nan_to_num(suits.astype(np.float32), nan=0.0, posinf=0.0, neginf=0.0)\n",
        "ss = suits.sum(axis=0, keepdims=True); ss[ss==0]=1; suits = suits/ss\n",
        "\n",
        "# Aggregate into 3 classes: [Sawah(1), Built-up(2), Others(3)]\n",
        "GROUPS = {\"Sawah\":[1], \"Lahan_Terbangun\":[2], \"Lainnya\":\"rest\"}\n",
        "cls_list = list(suit_classes.tolist()); stacks, names, used = [], [], set()\n",
        "for gname, members in GROUPS.items():\n",
        "    if members == \"rest\":\n",
        "        idx = [i for i in range(suits.shape[0]) if i not in used]\n",
        "    else:\n",
        "        idx = [cls_list.index(m) for m in members if m in cls_list]\n",
        "    stacks.append(np.nansum(suits[idx,...], axis=0).astype(np.float32) if len(idx) else np.zeros((H,W), np.float32))\n",
        "    used.update(idx); names.append(gname)\n",
        "SUIT_3 = np.stack(stacks, axis=0).astype(np.float32)\n",
        "ss3 = SUIT_3.sum(axis=0, keepdims=True); ss3[ss3==0]=1; SUIT_3 = SUIT_3/ss3\n",
        "print(\"Aggregated channels:\", names)\n",
        "\n",
        "# -------------------- UPI Constraint --------------------\n",
        "C_raw, _ = read_raster(os.path.join(SAWAH_DIR, \"Ske_UPI.tif\"))\n",
        "if C_raw.shape != (H,W): raise ValueError(f\"Ske_UPI shape {C_raw.shape} ≠ map shape {PL_24.shape}. Please align grids first.\")\n",
        "eligible = np.zeros_like(C_raw, dtype=bool)\n",
        "eligible[np.isfinite(C_raw) & (C_raw > 0)] = True\n",
        "valid = (PL_24 != NODATA)\n",
        "print(\"UPI Eligibility — proportion of eligible pixels:\", float((eligible & valid).mean()))\n",
        "\n",
        "# -------------------- Pressure (consistent with CA; no Markov) --------------------\n",
        "n2_2016 = neighborhood_fraction(PL_16, 2, NEIGH_SIZE)\n",
        "n2_2024 = neighborhood_fraction(PL_24, 2, NEIGH_SIZE)\n",
        "suit_BU  = SUIT_3[1]\n",
        "pressure_hist = (1.0 - NEIGH_WEIGHT)*suit_BU + NEIGH_WEIGHT*n2_2016\n",
        "pressure_proj = (1.0 - NEIGH_WEIGHT)*suit_BU + NEIGH_WEIGHT*n2_2024\n",
        "\n",
        "# -------------------- Endogenous change rate calibration --------------------\n",
        "# A) Eligible-only rate (strictest under constraint)\n",
        "mask_hist_cand = eligible & (PL_16 != NODATA) & ((PL_16==1) | (PL_16==3))\n",
        "changed_to_BU  = mask_hist_cand & (PL_24==2)\n",
        "denom_elig = int(mask_hist_cand.sum())\n",
        "num_elig   = int(changed_to_BU.sum())\n",
        "p_base_elig = (num_elig / denom_elig) if denom_elig > 0 else 0.0\n",
        "print(f\"[Calibration] p_base_elig (2016→2024, eligible non-BU→BU) = {p_base_elig:.8f} | samples={denom_elig}\")\n",
        "\n",
        "# B) Global fallback rate\n",
        "valid16 = (PL_16 != NODATA); valid24 = (PL_24 != NODATA)\n",
        "nonBU16 = valid16 & ((PL_16==1) | (PL_16==3))\n",
        "toBU_glob = nonBU16 & valid24 & (PL_24==2)\n",
        "denom_glob = int(nonBU16.sum())\n",
        "num_glob   = int(toBU_glob.sum())\n",
        "r_global = (num_glob / denom_glob) if denom_glob > 0 else 0.0\n",
        "print(f\"[Calibration] r_global (2016→2024, non-BU→BU, all valid) = {r_global:.8f} | samples={denom_glob}\")\n",
        "\n",
        "# C) Projection candidates: eligible & non-BU in 2024 (both 1 and 3)\n",
        "cand_proj = eligible & valid & ((PL_24==1) | (PL_24==3))\n",
        "N_cand = int(cand_proj.sum())\n",
        "\n",
        "# D) Expected total transitions (no manual target), amplified by policy\n",
        "if p_base_elig > 0:\n",
        "    E = p_base_elig * N_cand\n",
        "else:\n",
        "    E = r_global * N_cand\n",
        "    if E < 1 and N_cand > 0:\n",
        "        E = max(1.0, 0.001 * N_cand)\n",
        "E *= POLICY_INTENSITY  # strengthens expansion pressure\n",
        "\n",
        "# E) Normalize pressure to form baseline probability so Σ p ≈ E\n",
        "sum_press = float(np.nansum(pressure_proj[cand_proj])) if N_cand > 0 else 1.0\n",
        "alpha0 = (E / sum_press) if sum_press > 0 else 0.0\n",
        "\n",
        "p_map = np.zeros_like(pressure_proj, dtype=np.float32)\n",
        "p_map[cand_proj] = alpha0 * pressure_proj[cand_proj]\n",
        "\n",
        "# F) Apply source preference: rice fields more dominant, others still allowed\n",
        "mask1 = cand_proj & (PL_24==1)\n",
        "mask3 = cand_proj & (PL_24==3)\n",
        "p_map[mask1] *= W1\n",
        "p_map[mask3] *= W3\n",
        "\n",
        "# Re-normalize so Σp(after weights) ≈ E (still no fixed target)\n",
        "sum_p = float(np.nansum(p_map[cand_proj]))\n",
        "if sum_p > 0:\n",
        "    scale = E / sum_p\n",
        "    p_map[cand_proj] *= scale\n",
        "\n",
        "# Probability bounds for stochastic stability\n",
        "p_map = np.clip(p_map, 0.0, 0.9)\n",
        "print(f\"[Prob-map] N_cand={N_cand} | E_raw≈{E:.2f} | alpha0={alpha0:.6e} | Σp(after weights)≈{float(p_map[cand_proj].sum()):.2f}\")\n",
        "\n",
        "# -------------------- Probabilistic CA (no quantity target) --------------------\n",
        "rng = np.random.default_rng(RAND_SEED)\n",
        "\n",
        "def step_probabilistic_CA(current_map, p_map, allowed_change_mask, nodata=255):\n",
        "    \"\"\"One CA step: eligible non-BU (1 & 3) may transition to BU according to p_map.\"\"\"\n",
        "    out = current_map.copy()\n",
        "    valid = (current_map != nodata)\n",
        "    cand  = valid & allowed_change_mask & ((current_map==1) | (current_map==3))\n",
        "    if not np.any(cand): return out\n",
        "    toss = rng.random(current_map.shape, dtype=np.float32)\n",
        "    to_BU = cand & (toss < p_map)\n",
        "    out[to_BU] = 2\n",
        "    return out\n",
        "\n",
        "cur = PL_24.copy()\n",
        "for _ in range(QC_ITERS):\n",
        "    cur = step_probabilistic_CA(cur, p_map, eligible, nodata=NODATA)\n",
        "pred_2032 = cur\n",
        "\n",
        "# -------------------- Save & Summary --------------------\n",
        "out_tif = os.path.join(CHGDIR, \"Prediksi_2032_UPI_CA_prob_priorSawah_POLICY_noquota_nomarkov.tif\")\n",
        "save_with_colormap(pred_2032, PROFILE, out_tif)\n",
        "\n",
        "ha_pix = ha_per_pixel(PROFILE)\n",
        "luas24 = area_by_class(PL_24, ha_pix)\n",
        "luas32 = area_by_class(pred_2032, ha_pix)\n",
        "\n",
        "summary = pd.DataFrame([\n",
        "    [\"Sawah\",     luas24[1], luas32[1], luas32[1]-luas24[1]],\n",
        "    [\"Terbangun\", luas24[2], luas32[2], luas32[2]-luas24[2]],\n",
        "    [\"Lainnya\",   luas24[3], luas32[3], luas32[3]-luas24[3]],\n",
        "], columns=[\"Class\",\"2024 (ha)\",\"2032 UPI (ha)\",\"Δ(ha)\"])\n",
        "\n",
        "csv_out = os.path.join(REP_DIR, \"area_summary_2032_UPI_CA_prob_priorSawah_POLICY_noquota_nomarkov.csv\")\n",
        "summary.to_csv(csv_out, index=False)\n",
        "\n",
        "print(\"\\n=== PROJECTION 2032 — UPI (Probabilistic CA; prioritize rice fields; policy-intensity; no Markov) ===\")\n",
        "print(f\"[Info] Δ Built-up (ha) ≈ {(luas32[2]-luas24[2]):.2f} | Δ Sawah (ha) ≈ {(luas32[1]-luas24[1]):.2f}\")\n",
        "print(summary.round(2))\n",
        "print(\"✅ Saved:\", out_tif)\n",
        "print(\"✅ Saved:\", csv_out)\n",
        "\n",
        "# -------------------- Visualization --------------------\n",
        "def show_classmap(arr, title, nodata=255):\n",
        "    labels = ['Sawah (1)','Terbangun (2)','Lainnya (3)']\n",
        "    cmap = ListedColormap(['#2e8b57','#dc143c','#1e90ff'])\n",
        "    m = np.ma.masked_where(arr==nodata, arr)\n",
        "    plt.imshow(m, cmap=cmap, vmin=1, vmax=3); plt.title(title); plt.axis('off')\n",
        "    patches = [mpatches.Patch(color=cmap(i), label=labels[i]) for i in range(3)]\n",
        "    return patches\n",
        "\n",
        "plt.figure(figsize=(12,6), dpi=600)\n",
        "plt.subplot(1,2,2); legend_handles = show_classmap(pred_2032, \"UPI Scenario\")\n",
        "plt.legend(handles=legend_handles, loc='lower center', bbox_to_anchor=(0.5, -0.05), ncol=3, frameon=False)\n",
        "plt.tight_layout(); plt.show()\n"
      ],
      "metadata": {
        "id": "_k8UYzrSykhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **HYBRID Scenario**"
      ],
      "metadata": {
        "id": "JtzDkhfqy_-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# HYBRID Projection — Probabilistic CA (UPI ∪ B4B5-10%) — NO MARKOV\n",
        "# ============================================================\n",
        "# - No transition matrix (no T/T²)\n",
        "# - HYBRID eligibility = Ske_UPI ∪ (10% of B4B5 rice fields adaptively selected by pressure)\n",
        "# - Built-up (BU) class is absorbing; only 1/3 → 2 transitions allowed (1→3 implicitly blocked)\n",
        "# - Pressure: built-up suitability + built-up neighborhood density\n",
        "# - Non-quota mode: E = r_global(2016→2024, non-BU→BU) × POLICY_INTENSITY\n",
        "# - Farmland-loss suppression: low source-share, B4B5 protection (penalty + soft cap), edge softener\n",
        "# ============================================================\n",
        "\n",
        "# -------------------- Bootstrap: dependencies & mount --------------------\n",
        "import sys, os\n",
        "def _maybe_install_and_restart():\n",
        "    try:\n",
        "        import rasterio  # noqa\n",
        "        import numpy as np  # noqa\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(\"[Setup] Installing pinned versions...\", e)\n",
        "        os.system(\n",
        "            \"pip -q install --upgrade --force-reinstall --no-cache-dir \"\n",
        "            \" \\\"numpy==1.26.4\\\" \\\"rasterio==1.3.9\\\" \"\n",
        "            \" \\\"scipy==1.11.4\\\" \\\"pandas==2.1.4\\\" \\\"matplotlib==3.8.2\\\" \"\n",
        "            \" \\\"scikit-learn==1.3.2\\\" \\\"shapely==2.0.1\\\"\"\n",
        "        )\n",
        "        os.kill(os.getpid(), 9)\n",
        "_maybe_install_and_restart()\n",
        "\n",
        "try:\n",
        "    from google.colab import drive  # type: ignore\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "except Exception:\n",
        "    print(\"[Info] Not on Colab or Drive mount failed. Proceeding.\")\n",
        "\n",
        "# -------------------- Imports --------------------\n",
        "import numpy as np, rasterio, pandas as pd\n",
        "from scipy.ndimage import uniform_filter\n",
        "import matplotlib.pyplot as plt, matplotlib.patches as mpatches\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "# -------------------- Paths --------------------\n",
        "SAWAH_DIR = \"/content/drive/MyDrive/Sawah2\"    # PL_2016.tif, PL_2024.tif, SUIT_2016_all.npy, Ske_UPI.tif, Ske_B4B5.tif\n",
        "CHGDIR    = \"/content/drive/MyDrive/Land Use/Change_Analysis\"\n",
        "REP_DIR   = os.path.join(CHGDIR, \"reports\")\n",
        "os.makedirs(CHGDIR, exist_ok=True); os.makedirs(REP_DIR, exist_ok=True)\n",
        "\n",
        "# -------------------- Constants & Policy Settings --------------------\n",
        "NODATA       = 255\n",
        "NEIGH_WEIGHT = 0.40\n",
        "NEIGH_SIZE   = 9\n",
        "QC_ITERS     = 3           # reduce iterations to limit repeated 1→2 conversions\n",
        "RAND_SEED    = 42\n",
        "np.random.seed(RAND_SEED)\n",
        "\n",
        "# ===== Policy and Preferences (protective toward rice fields; still non-quota) =====\n",
        "POLICY_INTENSITY = 2.2     # total expansion scaling factor (2.0–2.6 typical)\n",
        "# Source weights (enhance 3→2, suppress 1→2)\n",
        "W1_UPI  = 3.0              # rice fields eligible via UPI\n",
        "W1_B4B5 = 0.6              # rice fields eligible only via B4B5 (weakened)\n",
        "W3_ALL  = 0.8              # class 3 allowed (increase to divert more transitions)\n",
        "# General protection for rice fields within B4B5 (beyond 10% allowance)\n",
        "PROTECT_B4B5_FACTOR = 0.35\n",
        "# Soft caps for 1→2 transitions (optional but effective)\n",
        "USE_SOFT_CAPS  = True\n",
        "CAP_P_SAWAH    = 0.04      # global cap for 1→2 probability (per iteration)\n",
        "CAP_P_B4B5     = 0.01      # stricter cap for 1→2 within B4B5\n",
        "# Source sharing: allocate expected E between rice-field and other sources (pressure-proportional)\n",
        "USE_SOURCE_SHARE = True\n",
        "E1_SHARE = 0.40            # share of E from rice-field sources (lower → smaller Δ sawah)\n",
        "# Edge softener: reduce 1→2 probabilities near dense BU edges\n",
        "EDGE_SOFTENER_STRENGTH = 0.5   # 0..1; 0.5 = 50% reduction near dense BU zones\n",
        "\n",
        "# -------------------- Utility Functions --------------------\n",
        "def read_raster(path):\n",
        "    if not os.path.exists(path): raise FileNotFoundError(f\"File not found: {path}\")\n",
        "    with rasterio.open(path) as src: return src.read(1), src.profile\n",
        "\n",
        "def save_with_colormap(arr, profile, path, nodata=255):\n",
        "    prof = profile.copy()\n",
        "    prof.update(dtype=rasterio.uint8, nodata=nodata, count=1, compress=\"lzw\",\n",
        "                height=arr.shape[0], width=arr.shape[1])\n",
        "    with rasterio.open(path, 'w', **prof) as dst:\n",
        "        dst.write(arr.astype(np.uint8), 1)\n",
        "        dst.write_colormap(1, {1:(46,139,87,255), 2:(220,20,60,255), 3:(30,144,255,255), 255:(0,0,0,0)})\n",
        "    print(\"✅ Saved:\", path)\n",
        "\n",
        "def ha_per_pixel(profile):\n",
        "    t = profile['transform']; return abs(t.a)*abs(t.e)/10_000.0\n",
        "\n",
        "def area_by_class(arr, ha_pix):\n",
        "    return {c: float((arr==c).sum())*ha_pix for c in (1,2,3)}\n",
        "\n",
        "def neighborhood_fraction(label_map, cls, size=5):\n",
        "    return uniform_filter((label_map==cls).astype(np.float32), size=size, mode='nearest')\n",
        "\n",
        "# -------------------- Load Maps --------------------\n",
        "PL_16,_       = read_raster(os.path.join(SAWAH_DIR,\"PL_2016.tif\"))\n",
        "PL_24, PROF24 = read_raster(os.path.join(SAWAH_DIR,\"PL_2024.tif\"))\n",
        "H, W = PL_24.shape\n",
        "\n",
        "SUIT_ALL = np.load(os.path.join(SAWAH_DIR,\"SUIT_2016_all.npy\")).astype(np.float32)\n",
        "if SUIT_ALL.ndim != 3 or SUIT_ALL.shape[1:] != (H,W):\n",
        "    raise ValueError(f\"SUIT_2016_all.npy shape {SUIT_ALL.shape} ≠ (C,{H},{W})\")\n",
        "\n",
        "SUIT_ALL = np.nan_to_num(SUIT_ALL, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "ss = SUIT_ALL.sum(axis=0, keepdims=True); ss[ss==0]=1; SUIT_ALL /= ss\n",
        "\n",
        "classes_path = os.path.join(SAWAH_DIR,\"SUIT_2016_all_classes.npy\")\n",
        "if os.path.exists(classes_path):\n",
        "    suit_classes = np.load(classes_path)\n",
        "else:\n",
        "    suit_classes = np.arange(SUIT_ALL.shape[0])\n",
        "cls_list = list(suit_classes.tolist())\n",
        "\n",
        "def agg_to_3(SUIT_ALL, cls_list):\n",
        "    stacks, used = [], set()\n",
        "    for members in ([1],[2],\"rest\"):\n",
        "        if members == \"rest\":\n",
        "            idx = [i for i in range(SUIT_ALL.shape[0]) if i not in used]\n",
        "        else:\n",
        "            idx = [cls_list.index(m) for m in members if m in cls_list]\n",
        "        stacks.append(np.nansum(SUIT_ALL[idx,...], axis=0).astype(np.float32) if len(idx) else np.zeros((H,W), np.float32))\n",
        "        used.update(idx)\n",
        "    SU3 = np.stack(stacks, axis=0).astype(np.float32)\n",
        "    s = SU3.sum(axis=0, keepdims=True); s[s==0]=1\n",
        "    return SU3/s\n",
        "\n",
        "SUIT_3 = agg_to_3(SUIT_ALL, cls_list)\n",
        "suit_BU = SUIT_3[1]\n",
        "\n",
        "# -------------------- HYBRID Eligibility: UPI ∪ 10% of B4B5 Rice Fields --------------------\n",
        "ELIG_UPI_raw, _ = read_raster(os.path.join(SAWAH_DIR,\"Ske_UPI.tif\"))\n",
        "ELIG_UPI = (np.isfinite(ELIG_UPI_raw) & (ELIG_UPI_raw==1))\n",
        "\n",
        "B4B5_raw, _ = read_raster(os.path.join(SAWAH_DIR,\"Ske_B4B5.tif\"))\n",
        "IN_B4B5 = (np.isfinite(B4B5_raw) & (B4B5_raw>0))\n",
        "\n",
        "sawah_in_b4b5 = (PL_24==1) & IN_B4B5\n",
        "n_prot = int(sawah_in_b4b5.sum()); quota = int(np.floor(0.10*n_prot)) if n_prot>0 else 0\n",
        "\n",
        "# Select 10% of B4B5 rice fields adaptively: suit_BU + BU neighborhood\n",
        "nb2 = neighborhood_fraction(PL_24, 2, size=7)\n",
        "cand_score = 0.8*suit_BU + 0.2*nb2\n",
        "ALLOW_SAWAH_B4B5 = np.zeros_like(PL_24, dtype=bool)\n",
        "if quota>0:\n",
        "    idx = np.flatnonzero(sawah_in_b4b5.ravel())\n",
        "    pick = idx if idx.size<=quota else idx[np.argsort(-cand_score.ravel()[idx])[:quota]]\n",
        "    ALLOW_SAWAH_B4B5.ravel()[pick] = True\n",
        "\n",
        "allowed_change = ELIG_UPI | ALLOW_SAWAH_B4B5\n",
        "valid = (PL_24 != NODATA)\n",
        "print(\"HYBRID Eligibility — proportion of eligible pixels:\", float((allowed_change & valid).mean()))\n",
        "\n",
        "# -------------------- Pressure (no Markov) --------------------\n",
        "n2_2024 = neighborhood_fraction(PL_24, 2, NEIGH_SIZE)\n",
        "pressure_proj = (1.0 - NEIGH_WEIGHT)*suit_BU + NEIGH_WEIGHT*n2_2024\n",
        "\n",
        "# Edge softener for rice fields\n",
        "edge_softener = 1.0 - EDGE_SOFTENER_STRENGTH * np.clip(n2_2024, 0.0, 1.0)\n",
        "\n",
        "# -------------------- Endogenous Calibration (non-BU→BU, 2016→2024) --------------------\n",
        "valid16 = (PL_16 != NODATA); valid24 = (PL_24 != NODATA)\n",
        "nonBU16 = valid16 & ((PL_16==1) | (PL_16==3))\n",
        "toBU_glob = nonBU16 & valid24 & (PL_24==2)\n",
        "denom_glob = int(nonBU16.sum()); num_glob = int(toBU_glob.sum())\n",
        "r_global = (num_glob / denom_glob) if denom_glob>0 else 0.0\n",
        "print(f\"[Calibration] r_global (2016→2024, non-BU→BU) = {r_global:.8f} | samples={denom_glob}\")\n",
        "\n",
        "cand_proj = allowed_change & valid & ((PL_24==1) | (PL_24==3))\n",
        "N_cand = int(cand_proj.sum())\n",
        "\n",
        "E = r_global * N_cand\n",
        "if E < 1 and N_cand > 0: E = max(1.0, 0.001 * N_cand)\n",
        "E *= POLICY_INTENSITY\n",
        "\n",
        "sum_press = float(np.nansum(pressure_proj[cand_proj])) if N_cand>0 else 1.0\n",
        "alpha0 = (E / sum_press) if sum_press>0 else 0.0\n",
        "\n",
        "p_map = np.zeros_like(pressure_proj, dtype=np.float32)\n",
        "p_map[cand_proj] = alpha0 * pressure_proj[cand_proj]\n",
        "\n",
        "# -------------------- Source Weights + B4B5 Protection + Soft Caps --------------------\n",
        "mask1_upi        = cand_proj & (PL_24==1) & ELIG_UPI\n",
        "mask1_b4b5_allow = cand_proj & (PL_24==1) & (~ELIG_UPI) & ALLOW_SAWAH_B4B5\n",
        "mask1_b4b5_all   = cand_proj & (PL_24==1) & IN_B4B5\n",
        "mask3_any        = cand_proj & (PL_24==3)\n",
        "\n",
        "p_map[mask1_upi]        *= W1_UPI * edge_softener[mask1_upi]\n",
        "p_map[mask1_b4b5_allow] *= W1_B4B5 * edge_softener[mask1_b4b5_allow]\n",
        "p_map[mask3_any]        *= W3_ALL\n",
        "\n",
        "# Apply general penalty for all rice fields in B4B5 corridor (even beyond 10% allowance)\n",
        "p_map[mask1_b4b5_all]   *= PROTECT_B4B5_FACTOR\n",
        "\n",
        "# Apply soft caps for 1→2\n",
        "if USE_SOFT_CAPS:\n",
        "    mask1_all = cand_proj & (PL_24==1)\n",
        "    p_map[mask1_all]      = np.minimum(p_map[mask1_all],      CAP_P_SAWAH)\n",
        "    p_map[mask1_b4b5_all] = np.minimum(p_map[mask1_b4b5_all], CAP_P_B4B5)\n",
        "\n",
        "# -------------------- Source Sharing (pressure-proportional; non-quota) --------------------\n",
        "if USE_SOURCE_SHARE:\n",
        "    cand1 = cand_proj & (PL_24==1)\n",
        "    cand3 = cand_proj & (PL_24==3)\n",
        "    E1 = E * E1_SHARE\n",
        "    E3 = E * (1.0 - E1_SHARE)\n",
        "\n",
        "    p1 = np.zeros_like(p_map, dtype=np.float32); p1[cand1] = p_map[cand1]\n",
        "    p3 = np.zeros_like(p_map, dtype=np.float32); p3[cand3] = p_map[cand3]\n",
        "\n",
        "    sum_p1 = float(np.nansum(p1[cand1])); sum_p3 = float(np.nansum(p3[cand3]))\n",
        "    p_map[:] = 0.0\n",
        "    if sum_p1 > 0: p_map[cand1] += p1[cand1] * (E1 / sum_p1)\n",
        "    if sum_p3 > 0: p_map[cand3] += p3[cand3] * (E3 / sum_p3)\n",
        "\n",
        "# Global re-normalization so Σp ≈ E\n",
        "sum_p = float(np.nansum(p_map[cand_proj]))\n",
        "if sum_p > 0:\n",
        "    p_map[cand_proj] *= (E / sum_p)\n",
        "\n",
        "p_map = np.clip(p_map, 0.0, 0.9)\n",
        "print(f\"[Prob-map] N_cand={N_cand} | E≈{E:.2f} | alpha0={alpha0:.6e} | Σp(after weights)≈{float(p_map[cand_proj].sum()):.2f}\")\n",
        "\n",
        "# -------------------- Probabilistic CA (BU absorbing; only 1/3→2) --------------------\n",
        "rng = np.random.default_rng(RAND_SEED)\n",
        "def step_probabilistic_CA(current_map, p_map, eligibility_mask, nodata=255):\n",
        "    out = current_map.copy()\n",
        "    valid = (current_map != nodata)\n",
        "    out[current_map==2] = 2  # BU absorbing\n",
        "    cand_to_BU = valid & eligibility_mask & ((current_map==1) | (current_map==3))\n",
        "    if np.any(cand_to_BU):\n",
        "        toss = rng.random(current_map.shape, dtype=np.float32)\n",
        "        to_BU = cand_to_BU & (toss < p_map)\n",
        "        out[to_BU] = 2\n",
        "    out[~valid] = nodata\n",
        "    return out\n",
        "\n",
        "cur = PL_24.copy()\n",
        "for _ in range(QC_ITERS):\n",
        "    cur = step_probabilistic_CA(cur, p_map, allowed_change, nodata=NODATA)\n",
        "\n",
        "pred_2032_hybrid = cur\n",
        "\n",
        "# -------------------- Summary & Save --------------------\n",
        "out_tif = os.path.join(CHGDIR, \"Prediksi_2032_HYBRID_Protective_noMarkov.tif\")\n",
        "save_with_colormap(pred_2032_hybrid, PROF24, out_tif)\n",
        "\n",
        "ha_pix = ha_per_pixel(PROF24)\n",
        "luas24 = area_by_class(PL_24, ha_pix)\n",
        "luas32 = area_by_class(pred_2032_hybrid, ha_pix)\n",
        "df = pd.DataFrame([\n",
        "    [\"Sawah\",     luas24[1], luas32[1], luas32[1]-luas24[1]],\n",
        "    [\"Terbangun\", luas24[2], luas32[2], luas32[2]-luas24[2]],\n",
        "    [\"Lainnya\",   luas24[3], luas32[3], luas32[3]-luas24[3]],\n",
        "], columns=[\"Class\",\"2024 (ha)\",\"2032 HYBRID (ha)\",\"Δ(ha)\"])\n",
        "print(\"\\n=== PROJECTION 2032 — HYBRID (Probabilistic; protective; no Markov; BU absorbing) ===\")\n",
        "print(df.round(2))\n",
        "\n",
        "csv_out = os.path.join(REP_DIR, \"area_summary_2032_HYBRID_Protective_noMarkov.csv\")\n",
        "df.to_csv(csv_out, index=False)\n",
        "print(\"✅ Saved:\", out_tif)\n",
        "print(\"✅ Saved:\", csv_out)\n",
        "\n",
        "# -------------------- Visualization --------------------\n",
        "def show_classmap(arr, title, nodata=255):\n",
        "    labels = ['Sawah (1)','Terbangun (2)','Lainnya (3)']\n",
        "    cmap = ListedColormap(['#2e8b57','#dc143c','#1e90ff'])\n",
        "    m = np.ma.masked_where(arr==nodata, arr)\n",
        "    plt.imshow(m, cmap=cmap, vmin=1, vmax=3); plt.title(title); plt.axis('off')\n",
        "    patches = [mpatches.Patch(color=cmap(i), label=labels[i]) for i in range(3)]\n",
        "    return patches\n",
        "\n",
        "plt.figure(figsize=(12,6), dpi=220)\n",
        "plt.subplot(1,2,1); _ = show_classmap(PL_24, \"OBSERVATION 2024\")\n",
        "plt.subplot(1,2,2); legend_handles = show_classmap(pred_2032_hybrid, \"PROJECTION 2032 — HYBRID (Protective)\")\n",
        "plt.legend(handles=legend_handles, loc='lower center', bbox_to_anchor=(0.5, -0.05), ncol=3, frameon=False)\n",
        "plt.tight_layout(); plt.show()\n"
      ],
      "metadata": {
        "id": "N8JJJ3SSzFI2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}