{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YGuSbWPt-4t"
      },
      "outputs": [],
      "source": [
        "# === Setup: install & mount ===\n",
        "!pip -q install rasterio geopandas shapely fiona scikit-learn joblib\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "# === Path dasar data (ubah jika perlu) ===\n",
        "SAWAH_DIR = \"/content/drive/MyDrive/Sawah2\"  # ganti ke folder kerjamu\n",
        "assert os.path.exists(SAWAH_DIR), f\"Folder tidak ditemukan: {SAWAH_DIR}\"\n",
        "\n",
        "# === Utilitas ===\n",
        "def read_raster(path):\n",
        "    \"\"\"Return (array, profile). Nodata dipetakan ke np.nan (float32).\"\"\"\n",
        "    assert os.path.exists(path), f\"Tidak ditemukan: {path}\"\n",
        "    with rasterio.open(path) as src:\n",
        "        arr = src.read(1)  # biarkan dtype asli (bisa int utk kelas)\n",
        "        nod = src.nodata\n",
        "        prof = src.profile.copy()\n",
        "        # jika array bukan float, tetap biarkan; np.nan butuh float ‚Üí tangani hanya jika nodata ada\n",
        "        if nod is not None and np.issubdtype(arr.dtype, np.number):\n",
        "            arr = arr.astype('float32', copy=False)\n",
        "            arr = np.where((arr == nod) | (~np.isfinite(arr)), np.nan, arr)\n",
        "        return arr, prof\n",
        "\n",
        "def norm01(a):\n",
        "    \"\"\"Normalisasi 0‚Äì1 abaikan NaN.\"\"\"\n",
        "    a = a.astype('float32', copy=False)\n",
        "    m = np.nanmin(a); M = np.nanmax(a)\n",
        "    if not np.isfinite(m) or not np.isfinite(M) or M == m:\n",
        "        return np.zeros_like(a, dtype='float32')\n",
        "    out = (a - m) / (M - m)\n",
        "    # pertahankan NaN\n",
        "    out[~np.isfinite(a)] = np.nan\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Random Forest‚ÄìBased Suitability Mapping (2008‚Äì2016)**"
      ],
      "metadata": {
        "id": "5Vjuo5xmuDVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "==============================================================\n",
        "Script A ‚Äî Random Forest & Suitability Mapping (2008) ‚Äî 3-Channel\n",
        "==============================================================\n",
        "\n",
        "Author  : Firmaness\n",
        "Date    : 2025-11-11\n",
        "Version : 1.0\n",
        "Purpose : Train a Random Forest model to generate 3-channel\n",
        "          land-use suitability maps (Paddy Field, Built-up Land, Others)\n",
        "          for the 2008 baseline year.\n",
        "\n",
        "Environment:\n",
        "    Python 3.10 (Google Colab)\n",
        "    scikit-learn 1.3, numpy 1.24, pandas 2.0, rasterio 1.3,\n",
        "    geopandas 0.13, shapely 2.0, matplotlib 3.7, statsmodels 0.14\n",
        "\"\"\"\n",
        "\n",
        "import joblib\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Optional: required only when writing GeoTIFF multi-band output\n",
        "# import rasterio\n",
        "\n",
        "# =============================================================\n",
        "# 1) LOAD DATA\n",
        "# =============================================================\n",
        "\n",
        "# Target variable (dependent variable)\n",
        "PL_08, PROFILE = read_raster(os.path.join(SAWAH_DIR, \"PL_2008.tif\"))\n",
        "\n",
        "# Predictor factors selected from VIF analysis\n",
        "CAT_FACTORS = [\"KL.tif\", \"ZNT_Edit.tif\"]  # categorical\n",
        "CONT_FACTORS = [\n",
        "    \"Jalan_Arteri.tif\", \"Jalan_Kolektor.tif\", \"Jalan_Lokal.tif\",\n",
        "    \"Distribusi_2008.tif\"                   # additional factor for 2008\n",
        "]\n",
        "\n",
        "# =============================================================\n",
        "# 2) CONFIGURATION FOR 3-CHANNEL AGGREGATION\n",
        "#    Define class grouping (original PL_2008 / rf.classes_) ‚Üí 3 groups\n",
        "#    Example: 1 = Paddy field, 2 = Built-up, others = Remaining\n",
        "# =============================================================\n",
        "\n",
        "GROUPS = {\n",
        "    \"Paddy_Field\": [1],         # adjust based on class code in PL_2008\n",
        "    \"Built_Up_Land\": [2],       # adjust based on built-up land code\n",
        "    \"Others\": \"rest\"            # remaining classes not listed above\n",
        "}\n",
        "\n",
        "# =============================================================\n",
        "# 3) UTILITY FUNCTIONS\n",
        "# =============================================================\n",
        "\n",
        "def load_factors_stack(folder):\n",
        "    \"\"\"\n",
        "    Load and normalize predictor raster layers.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    folder : str\n",
        "        Directory path containing raster layers.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    factors : np.ndarray\n",
        "        Stacked raster array (H, W, B).\n",
        "    names : list[str]\n",
        "        List of factor names.\n",
        "    cat_idx : list[int]\n",
        "        Indices of categorical variables.\n",
        "    \"\"\"\n",
        "    bands, names, cat_idx = [], [], []\n",
        "\n",
        "    # Categorical factors: replace NaN with -1 sentinel, keep as float32\n",
        "    for nm in CAT_FACTORS:\n",
        "        a, _ = read_raster(os.path.join(folder, nm))\n",
        "        a_cat = np.where(np.isfinite(a), a, -1).astype(\"float32\")\n",
        "        bands.append(a_cat)\n",
        "        names.append(nm)\n",
        "        cat_idx.append(len(bands) - 1)\n",
        "\n",
        "    # Continuous factors: normalize 0‚Äì1 (keep NaN as-is)\n",
        "    for nm in CONT_FACTORS:\n",
        "        a, _ = read_raster(os.path.join(folder, nm))\n",
        "        bands.append(norm01(a))\n",
        "        names.append(nm)\n",
        "\n",
        "    return np.stack(bands, axis=-1), names, cat_idx  # (H, W, B)\n",
        "\n",
        "\n",
        "FACTORS_2008, FACTOR_NAMES, CAT_IDX = load_factors_stack(SAWAH_DIR)\n",
        "\n",
        "# =============================================================\n",
        "# 4) RANDOM FOREST TRAINING\n",
        "# =============================================================\n",
        "\n",
        "def make_train_arrays(factors, target, cat_idx, nodata_class=255):\n",
        "    \"\"\"\n",
        "    Prepare valid training samples for model fitting.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    factors : np.ndarray\n",
        "        Stacked predictor variables (H, W, B).\n",
        "    target : np.ndarray\n",
        "        Target land-use raster (H, W).\n",
        "    cat_idx : list[int]\n",
        "        Indices of categorical factors.\n",
        "    nodata_class : int\n",
        "        Value representing no-data pixels.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X : np.ndarray\n",
        "        Predictor samples.\n",
        "    y : np.ndarray\n",
        "        Target classes.\n",
        "    \"\"\"\n",
        "    H, W, B = factors.shape\n",
        "    X = factors.reshape(-1, B)\n",
        "    y = target.reshape(-1)\n",
        "\n",
        "    m = np.isfinite(y) & (y != nodata_class)\n",
        "    for b in range(B):\n",
        "        if b in cat_idx:\n",
        "            m &= np.isfinite(X[:, b]) & (X[:, b] != -1)\n",
        "        else:\n",
        "            m &= np.isfinite(X[:, b])\n",
        "\n",
        "    return X[m], y[m].astype(int)\n",
        "\n",
        "\n",
        "def tune_and_fit_rf(factors, target, factor_names, cat_idx, sample_size=50_000, seed=42):\n",
        "    \"\"\"\n",
        "    Tune hyperparameters and fit the Random Forest classifier.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    factors : np.ndarray\n",
        "        Predictor variables.\n",
        "    target : np.ndarray\n",
        "        Target land-use classes.\n",
        "    factor_names : list[str]\n",
        "        Predictor variable names.\n",
        "    cat_idx : list[int]\n",
        "        Indices of categorical factors.\n",
        "    sample_size : int, optional\n",
        "        Number of random samples used for tuning.\n",
        "    seed : int, optional\n",
        "        Random seed for reproducibility.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    rf : RandomForestClassifier\n",
        "        Trained Random Forest model.\n",
        "    \"\"\"\n",
        "    from numpy.random import RandomState\n",
        "\n",
        "    X, y = make_train_arrays(factors, target, cat_idx)\n",
        "\n",
        "    if len(y) > sample_size:\n",
        "        rng = RandomState(seed)\n",
        "        idx = rng.choice(len(y), size=sample_size, replace=False)\n",
        "        X_sub, y_sub = X[idx], y[idx]\n",
        "    else:\n",
        "        X_sub, y_sub = X, y\n",
        "\n",
        "    param_dist = {\n",
        "        \"n_estimators\": [100, 150, 200, 250, 300],\n",
        "        \"max_depth\": [20, 30, 40, None],\n",
        "        \"min_samples_split\": [2, 5, 10, 20],\n",
        "        \"min_samples_leaf\": [1, 2, 4, 10],\n",
        "        \"max_features\": ['sqrt', 'log2', None]\n",
        "    }\n",
        "\n",
        "    base = RandomForestClassifier(\n",
        "        class_weight=\"balanced\", n_jobs=-1, random_state=seed\n",
        "    )\n",
        "\n",
        "    search = RandomizedSearchCV(\n",
        "        base, param_distributions=param_dist, n_iter=10, cv=3,\n",
        "        random_state=seed, verbose=1, n_jobs=-1\n",
        "    )\n",
        "    search.fit(X_sub, y_sub)\n",
        "    rf = search.best_estimator_\n",
        "\n",
        "    print(\"Best parameters:\", search.best_params_)\n",
        "    rf.fit(X, y)\n",
        "    print(\"\\nRF report (full training):\\n\", classification_report(y, rf.predict(X)))\n",
        "    print(\"Trained classes (rf.classes_):\", rf.classes_)\n",
        "\n",
        "    return rf\n",
        "\n",
        "\n",
        "RF_08 = tune_and_fit_rf(FACTORS_2008, PL_08, FACTOR_NAMES, CAT_IDX)\n",
        "\n",
        "# Save trained model\n",
        "joblib.dump(RF_08, os.path.join(SAWAH_DIR, \"RF_2008.pkl\"))\n",
        "\n",
        "# =============================================================\n",
        "# 5) PREDICT PROBABILITIES & BUILD SUITABILITY MAP (ALL CLASSES)\n",
        "# =============================================================\n",
        "\n",
        "def predict_proba_batched(rf, X_flat, batch=500_000):\n",
        "    \"\"\"Predict probabilities in batches to avoid memory overflow.\"\"\"\n",
        "    out = []\n",
        "    N = X_flat.shape[0]\n",
        "    for i in range(0, N, batch):\n",
        "        out.append(rf.predict_proba(X_flat[i:i + batch]))\n",
        "    return np.vstack(out)\n",
        "\n",
        "\n",
        "def build_suitability_map(rf, factors):\n",
        "    \"\"\"\n",
        "    Build suitability probability maps for all classes.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    rf : RandomForestClassifier\n",
        "        Trained RF model.\n",
        "    factors : np.ndarray\n",
        "        Stacked predictor array.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    suit : np.ndarray\n",
        "        Suitability map for all classes (C, H, W).\n",
        "    classes : np.ndarray\n",
        "        List of class labels corresponding to RF output order.\n",
        "    \"\"\"\n",
        "    H, W, B = factors.shape\n",
        "    X = factors.reshape(-1, B).copy()\n",
        "\n",
        "    # Replace NaN with 0 before prediction (categorical -1 remains)\n",
        "    nanmask = ~np.isfinite(X)\n",
        "    if nanmask.any():\n",
        "        X[nanmask] = 0\n",
        "\n",
        "    proba = predict_proba_batched(rf, X, batch=500_000)\n",
        "\n",
        "    classes = np.array(sorted(rf.classes_))\n",
        "    C = len(classes)\n",
        "    suit = np.zeros((C, H * W), np.float32)\n",
        "\n",
        "    # rf.predict_proba returns probabilities in rf.classes_ order (not sorted)\n",
        "    for k, cls in enumerate(rf.classes_):\n",
        "        ch = np.where(classes == cls)[0][0]\n",
        "        suit[ch, :] = proba[:, k]\n",
        "\n",
        "    return suit.reshape(C, H, W), classes\n",
        "\n",
        "\n",
        "SUIT_2008_ALL, SUIT_CLASSES = build_suitability_map(RF_08, FACTORS_2008)\n",
        "\n",
        "# Save full-class suitability maps\n",
        "np.save(os.path.join(SAWAH_DIR, \"SUIT_2008_all.npy\"), SUIT_2008_ALL)\n",
        "np.save(os.path.join(SAWAH_DIR, \"SUIT_2008_all_classes.npy\"), SUIT_CLASSES)\n",
        "print(\"‚úÖ Suitability (all classes) saved to:\", os.path.join(SAWAH_DIR, \"SUIT_2008_all.npy\"))\n",
        "\n",
        "# =============================================================\n",
        "# 6) AGGREGATE TO 3 CHANNELS: Paddy, Built-up, Others\n",
        "# =============================================================\n",
        "\n",
        "def aggregate_to_three_channels(suit_all, classes, groups_cfg):\n",
        "    \"\"\"\n",
        "    Aggregate suitability probabilities into 3 main land-use groups.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    suit_all : np.ndarray\n",
        "        Full-class suitability (C, H, W).\n",
        "    classes : np.ndarray\n",
        "        Land-use class codes.\n",
        "    groups_cfg : dict\n",
        "        Group configuration, e.g., {\"Paddy_Field\": [1], \"Built_Up_Land\": [2], \"Others\": \"rest\"}.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    suit3 : np.ndarray\n",
        "        Aggregated suitability (3, H, W).\n",
        "    names : list[str]\n",
        "        Channel names in the same order as groups_cfg.\n",
        "    \"\"\"\n",
        "    C, H, W = suit_all.shape\n",
        "    cls_list = list(classes.tolist())\n",
        "\n",
        "    names, stacks = [], []\n",
        "    used_indices = set()\n",
        "\n",
        "    for gname, members in groups_cfg.items():\n",
        "        if members == \"rest\":\n",
        "            idx = [i for i in range(C) if i not in used_indices]\n",
        "        else:\n",
        "            idx = [cls_list.index(m) for m in members if m in cls_list]\n",
        "        if len(idx) == 0:\n",
        "            stacks.append(np.zeros((H, W), dtype=np.float32))\n",
        "        else:\n",
        "            used_indices.update(idx)\n",
        "            stacks.append(np.nansum(suit_all[idx, ...], axis=0).astype(np.float32))\n",
        "        names.append(gname)\n",
        "\n",
        "    suit3 = np.stack(stacks, axis=0).astype(np.float32)\n",
        "    return suit3, names\n",
        "\n",
        "\n",
        "SUIT_2008_3, SUIT3_NAMES = aggregate_to_three_channels(SUIT_2008_ALL, SUIT_CLASSES, GROUPS)\n",
        "\n",
        "# Save 3-channel suitability arrays\n",
        "np.save(os.path.join(SAWAH_DIR, \"SUIT_2008_3ch.npy\"), SUIT_2008_3)\n",
        "np.save(os.path.join(SAWAH_DIR, \"SUIT_2008_3ch_names.npy\"), np.array(SUIT3_NAMES))\n",
        "print(\"‚úÖ Suitability 3-channel (\", SUIT3_NAMES, \") saved to:\", os.path.join(SAWAH_DIR, \"SUIT_2008_3ch.npy\"))\n",
        "\n",
        "# =============================================================\n",
        "# 7) OPTIONAL ‚Äî SAVE AS GEOTIFF 3-BAND STACK\n",
        "# =============================================================\n",
        "\"\"\"\n",
        "with rasterio.open(os.path.join(SAWAH_DIR, \"PL_2008.tif\")) as src_ref:\n",
        "    prof = src_ref.profile.copy()\n",
        "    prof.update(count=3, dtype='float32', nodata=np.float32(np.nan), compress='lzw')\n",
        "    outp = os.path.join(SAWAH_DIR, \"SUIT_2008_3ch.tif\")\n",
        "    with rasterio.open(outp, 'w', **prof) as dst:\n",
        "        for i in range(3):\n",
        "            dst.write(SUIT_2008_3[i].astype('float32'), i + 1)\n",
        "        # Save band names as metadata\n",
        "        dst.update_tags(1, name=SUIT3_NAMES[0])\n",
        "        dst.update_tags(2, name=SUIT3_NAMES[1])\n",
        "        dst.update_tags(3, name=SUIT3_NAMES[2])\n",
        "    print(\"üó∫Ô∏è GeoTIFF 3-band file saved:\", outp)\n",
        "\"\"\"\n",
        "\n",
        "# =============================================================\n",
        "# 8) NOTES\n",
        "# =============================================================\n",
        "# - Ensure GROUPS match the class codes in PL_2008.\n",
        "# - If codes differ (e.g., 10 = Paddy_Field, 20 = Built_Up), update the GROUPS dictionary.\n",
        "# - The \"Others\" channel automatically sums unlisted classes if set to \"rest\".\n",
        "# - The final GeoTIFF output will have 3 bands representing each land-use group.\n"
      ],
      "metadata": {
        "id": "23H7ZWKIuH1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Random Forest‚ÄìBased Suitability Mapping (2016‚Äì2024)**"
      ],
      "metadata": {
        "id": "Tx9e1RedutOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== Script A ‚Äî Random Forest & Suitability (2016) ‚Äî 3-Channel =====================\n",
        "import joblib\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# (Optional) Only required when writing multi-band GeoTIFF output\n",
        "# import rasterio\n",
        "\n",
        "# =============================================================\n",
        "# 1) LOAD DATA\n",
        "# =============================================================\n",
        "YEAR = 2016\n",
        "PL_YR_PATH = os.path.join(SAWAH_DIR, f\"PL_{YEAR}.tif\")\n",
        "PL_YR, PROFILE = read_raster(PL_YR_PATH)  # <-- TARGET (dependent variable)\n",
        "print(\"Loaded:\", PL_YR_PATH)\n",
        "\n",
        "# Predictor factors selected from VIF results (keep identical to Script 2008 ‚Äî only the target year differs)\n",
        "CAT_FACTORS  = [\"KL.tif\", \"ZNT_Edit.tif\"]  # categorical\n",
        "CONT_FACTORS = [\n",
        "    \"Jalan_Arteri.tif\", \"Jalan_Kolektor.tif\", \"Jalan_Lokal.tif\",\n",
        "    \"Distribusi_2016.tif\"                   # same as Script 2008 (only year differs)\n",
        "]\n",
        "\n",
        "# =============================================================\n",
        "# 2) 3-CHANNEL AGGREGATION CONFIGURATION\n",
        "#    Mapping of ORIGINAL CLASSES (codes in PL_YEAR / rf.classes_) ‚Üí 3 groups\n",
        "#    UPDATE the list below based on your legend.\n",
        "#    Common example: 1=Paddy Field, 2=Built-up, others=Remaining\n",
        "#    If unsure about class codes, run once to print rf.classes_.\n",
        "# =============================================================\n",
        "GROUPS = {\n",
        "    \"Sawah\": [1],                # adjust according to the paddy field class code in PL\n",
        "    \"Lahan_Terbangun\": [2],      # adjust according to built-up land class code in PL\n",
        "    \"Lainnya\": \"rest\"            # remaining classes not listed above\n",
        "}\n",
        "\n",
        "# =============================================================\n",
        "# 3) UTILITY FUNCTIONS\n",
        "# =============================================================\n",
        "\n",
        "def load_factors_stack(folder):\n",
        "    bands = []; names = []; cat_idx = []\n",
        "    # CATEGORICAL: NaN -> -1 (sentinel), then save as float32 (remain -1.0)\n",
        "    for nm in CAT_FACTORS:\n",
        "        a, _ = read_raster(os.path.join(folder, nm))\n",
        "        a_cat = np.where(np.isfinite(a), a, -1).astype('float32')\n",
        "        bands.append(a_cat); names.append(nm); cat_idx.append(len(bands)-1)\n",
        "    # CONTINUOUS: normalize to 0‚Äì1 (keep NaN as-is)\n",
        "    for nm in CONT_FACTORS:\n",
        "        a, _ = read_raster(os.path.join(folder, nm))\n",
        "        bands.append(norm01(a)); names.append(nm)\n",
        "    return np.stack(bands, axis=-1), names, cat_idx  # (H, W, B)\n",
        "\n",
        "FACTORS_YR, FACTOR_NAMES, CAT_IDX = load_factors_stack(SAWAH_DIR)\n",
        "\n",
        "# =============================================================\n",
        "# 4) RANDOM FOREST TRAINING\n",
        "# =============================================================\n",
        "\n",
        "def make_train_arrays(factors, target, cat_idx, nodata_class=255):\n",
        "    \"\"\"\n",
        "    Prepare valid training samples for model fitting.\n",
        "    \"\"\"\n",
        "    H, W, B = factors.shape\n",
        "    X = factors.reshape(-1, B)\n",
        "    y = target.reshape(-1)\n",
        "\n",
        "    m = np.isfinite(y) & (y != nodata_class)          # valid target pixels\n",
        "    for b in range(B):\n",
        "        if b in cat_idx:\n",
        "            m &= (np.isfinite(X[:, b]) & (X[:, b] != -1))  # categorical: exclude sentinel\n",
        "        else:\n",
        "            m &= np.isfinite(X[:, b])                      # continuous: must be finite\n",
        "\n",
        "    return X[m], y[m].astype(int)\n",
        "\n",
        "\n",
        "def tune_and_fit_rf(factors, target, factor_names, cat_idx, sample_size=50_000, seed=42):\n",
        "    \"\"\"\n",
        "    Tune hyperparameters and fit the Random Forest classifier.\n",
        "    \"\"\"\n",
        "    from numpy.random import RandomState\n",
        "    X, y = make_train_arrays(factors, target, cat_idx)\n",
        "    if len(y) > sample_size:\n",
        "        rng = RandomState(seed)\n",
        "        idx = rng.choice(len(y), size=sample_size, replace=False)\n",
        "        X_sub, y_sub = X[idx], y[idx]\n",
        "    else:\n",
        "        X_sub, y_sub = X, y\n",
        "\n",
        "    param_dist = {\n",
        "        \"n_estimators\":      [100, 150, 200, 250, 300],\n",
        "        \"max_depth\":         [20, 30, 40, None],\n",
        "        \"min_samples_split\": [2, 5, 10, 20],\n",
        "        \"min_samples_leaf\":  [1, 2, 4, 10],\n",
        "        \"max_features\":      ['sqrt', 'log2', None]\n",
        "    }\n",
        "    base = RandomForestClassifier(class_weight=\"balanced\", n_jobs=-1, random_state=seed)\n",
        "    search = RandomizedSearchCV(base, param_distributions=param_dist, n_iter=10, cv=3,\n",
        "                                random_state=seed, verbose=1, n_jobs=-1)\n",
        "    search.fit(X_sub, y_sub)\n",
        "    rf = search.best_estimator_\n",
        "    print(\"Best parameters:\", search.best_params_)\n",
        "    rf.fit(X, y)\n",
        "    print(\"\\nRF report (full training):\\n\", classification_report(y, rf.predict(X)))\n",
        "    print(\"Trained classes (rf.classes_):\", rf.classes_)\n",
        "    return rf\n",
        "\n",
        "RF_YR = tune_and_fit_rf(FACTORS_YR, PL_YR, FACTOR_NAMES, CAT_IDX)\n",
        "\n",
        "# Save trained model\n",
        "joblib.dump(RF_YR, os.path.join(SAWAH_DIR, f\"RF_{YEAR}.pkl\"))\n",
        "\n",
        "# =============================================================\n",
        "# 5) PREDICT PROBABILITIES & BUILD SUITABILITY MAPS (ALL CLASSES)\n",
        "# =============================================================\n",
        "\n",
        "def predict_proba_batched(rf, X_flat, batch=500_000):\n",
        "    out = []; N = X_flat.shape[0]\n",
        "    for i in range(0, N, batch):\n",
        "        out.append(rf.predict_proba(X_flat[i:i+batch]))\n",
        "    return np.vstack(out)\n",
        "\n",
        "\n",
        "def build_suitability_map(rf, factors):\n",
        "    \"\"\"\n",
        "    Build suitability probability maps for all land-use classes.\n",
        "    \"\"\"\n",
        "    H, W, B = factors.shape\n",
        "    X = factors.reshape(-1, B).copy()\n",
        "    # Fill NaN with 0 before prediction (categorical values with -1 remain unchanged)\n",
        "    nanmask = ~np.isfinite(X)\n",
        "    if nanmask.any():\n",
        "        X[nanmask] = 0\n",
        "    proba = predict_proba_batched(rf, X, batch=500_000)\n",
        "\n",
        "    classes = np.array(sorted(rf.classes_))\n",
        "    C = len(classes)\n",
        "    suit = np.zeros((C, H * W), np.float32)\n",
        "    # rf.predict_proba returns probabilities in rf.classes_ order (not sorted)\n",
        "    for k, cls in enumerate(rf.classes_):\n",
        "        ch = np.where(classes == cls)[0][0]\n",
        "        suit[ch, :] = proba[:, k]\n",
        "    return suit.reshape(C, H, W), classes\n",
        "\n",
        "SUIT_YR_ALL, SUIT_CLASSES = build_suitability_map(RF_YR, FACTORS_YR)\n",
        "\n",
        "# Save suitability maps (NPY) ‚Äî all classes\n",
        "np.save(os.path.join(SAWAH_DIR, f\"SUIT_{YEAR}_all.npy\"), SUIT_YR_ALL)\n",
        "np.save(os.path.join(SAWAH_DIR, f\"SUIT_{YEAR}_all_classes.npy\"), SUIT_CLASSES)\n",
        "print(\"‚úÖ Suitability (all classes) saved:\", os.path.join(SAWAH_DIR, f\"SUIT_{YEAR}_all.npy\"))\n",
        "\n",
        "# =============================================================\n",
        "# 6) AGGREGATE INTO 3 CHANNELS: Sawah, Lahan Terbangun, Lainnya\n",
        "#    Group-level probability = sum of probabilities of member classes\n",
        "# =============================================================\n",
        "\n",
        "def aggregate_to_three_channels(suit_all, classes, groups_cfg):\n",
        "    \"\"\"\\\n",
        "    suit_all : (C,H,W) float32   ‚Äî suitability for all classes\n",
        "    classes  : (C,)              ‚Äî class values (integer codes from PL)\n",
        "    groups_cfg: dict             ‚Äî mapping {\"GroupName\": [codes...]} or \"rest\"\n",
        "    Returns\n",
        "    -------\n",
        "    suit3 : (3,H,W) float32  ‚Äî channels follow the order of group_cfg keys\n",
        "    names : list[str]        ‚Äî channel names\n",
        "    \"\"\"\n",
        "    C, H, W = suit_all.shape\n",
        "    cls_list = list(classes.tolist())\n",
        "\n",
        "    names = []; stacks = []; used_indices = set()\n",
        "    for gname, members in groups_cfg.items():\n",
        "        if members == \"rest\":\n",
        "            idx = [i for i in range(C) if i not in used_indices]\n",
        "        else:\n",
        "            idx = [cls_list.index(m) for m in members if m in cls_list]\n",
        "        if len(idx) == 0:\n",
        "            stacks.append(np.zeros((H, W), dtype=np.float32))\n",
        "        else:\n",
        "            used_indices.update(idx)\n",
        "            stacks.append(np.nansum(suit_all[idx, ...], axis=0).astype(np.float32))\n",
        "        names.append(gname)\n",
        "\n",
        "    suit3 = np.stack(stacks, axis=0).astype(np.float32)\n",
        "    return suit3, names\n",
        "\n",
        "SUIT_YR_3, SUIT3_NAMES = aggregate_to_three_channels(SUIT_YR_ALL, SUIT_CLASSES, GROUPS)\n",
        "\n",
        "# Save 3-channel NPY (order follows SUIT3_NAMES)\n",
        "np.save(os.path.join(SAWAH_DIR, f\"SUIT_{YEAR}_3ch.npy\"), SUIT_YR_3)\n",
        "np.save(os.path.join(SAWAH_DIR, f\"SUIT_{YEAR}_3ch_names.npy\"), np.array(SUIT3_NAMES))\n",
        "print(\"‚úÖ Suitability 3-channel (\", SUIT3_NAMES, \") saved:\", os.path.join(SAWAH_DIR, f\"SUIT_{YEAR}_3ch.npy\"))\n",
        "\n",
        "# =============================================================\n",
        "# 7) (OPTIONAL) SAVE AS 3-BAND GEOTIFF (STACKED)\n",
        "#    Band-1 = Sawah, Band-2 = Lahan_Terbangun, Band-3 = Lainnya\n",
        "#    Activate by uncommenting the block below\n",
        "# =============================================================\n",
        "\"\"\"\n",
        "with rasterio.open(os.path.join(SAWAH_DIR, f\"PL_{YEAR}.tif\")) as src_ref:\n",
        "    prof = src_ref.profile.copy()\n",
        "    prof.update(count=3, dtype='float32', nodata=np.float32(np.nan), compress='lzw')\n",
        "    outp = os.path.join(SAWAH_DIR, f\"SUIT_{YEAR}_3ch.tif\")\n",
        "    with rasterio.open(outp, 'w', **prof) as dst:\n",
        "        for i in range(3):\n",
        "            dst.write(SUIT_YR_3[i].astype('float32'), i+1)\n",
        "        # Save band names as metadata\n",
        "        dst.update_tags(1, name=SUIT3_NAMES[0])\n",
        "        dst.update_tags(2, name=SUIT3_NAMES[1])\n",
        "        dst.update_tags(3, name=SUIT3_NAMES[2])\n",
        "    print(\"üó∫Ô∏è GeoTIFF 3-band file saved:\", outp)\n",
        "\"\"\"\n",
        "\n",
        "# =============================================================\n",
        "# 8) NOTES\n",
        "# - Structure, functions, and factors are identical to Script 2008.\n",
        "# - The only difference is using the 2016 target map, and outputs are named according to YEAR.\n",
        "# - If changing the yearly factor (e.g., Distribusi_2016.tif), manually update CONT_FACTORS to keep consistency across years.\n"
      ],
      "metadata": {
        "id": "qPs8u5tNuUYQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}